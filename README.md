# Apache Airflow em Docker (stack leve para desenvolvimento local)

Este repositÃ³rio traz uma configuraÃ§Ã£o do **Apache Airflow** pronta para rodar em ambiente local via **Docker Compose**, utilizando o **PostgreSQL 13** como backend de metadados.

A proposta Ã© oferecer um ambiente **mÃ­nimo e funcional** para desenvolvimento e testes de DAGs, inspirado na [documentaÃ§Ã£o oficial do Airflow](https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html), mas simplificado e otimizado para rodar localmente.

---

## ğŸ” O que estÃ¡ incluÃ­do?

- **Airflow Services**:  
  - `airflow-apiserver`  
  - `airflow-scheduler`  
  - `airflow-dag-processor`  
  - `airflow-triggerer`  
  - `airflow-init` (migraÃ§Ã£o + criaÃ§Ã£o de usuÃ¡rio admin)  
  - `airflow-cli` (opcional para debug)  

- **Banco de dados**:  
  - `postgres:13` rodando como serviÃ§o dentro do Compose.  

- **Volumes mapeados** para facilitar o desenvolvimento:  
  - `./dags` â†’ DAGs  
  - `./logs` â†’ Logs  
  - `./plugins` â†’ Plugins customizados  
  - `./config` â†’ ConfiguraÃ§Ãµes  

---

## ğŸš€ Como rodar

1. Clone este repositÃ³rio:
   ```bash
   git clone https://github.com/<sua-org>/<seu-repo>.git
   cd <seu-repo>
   ```

2. DÃª permissÃ£o de execuÃ§Ã£o ao script:
   ```bash
   chmod +x run.sh
   ```

3. Execute:
   ```bash
   ./run.sh
   ```

Esse script:
- Cria a pasta `airflow-docker` com a estrutura mÃ­nima (`dags`, `logs`, `plugins`, `config`).
- Gera um `.env` padrÃ£o (caso nÃ£o exista).
- Executa `airflow-init` para preparar o banco de dados no Postgres 13 e criar o usuÃ¡rio admin.
- Sobe todos os contÃªineres do Airflow em segundo plano.
- Aguarda atÃ© que o **API Server** esteja saudÃ¡vel em:  
  ğŸ‘‰ [http://localhost:8080/api/v2/version](http://localhost:8080/api/v2/version)

---

## ğŸ“‚ Estrutura do projeto

```
.
â”œâ”€â”€ docker-compose.yml   # ServiÃ§os Airflow + Postgres 13
â”œâ”€â”€ run.sh               # Script automatizado para subir o ambiente
â”œâ”€â”€ dags/                # Suas DAGs vÃ£o aqui
â”œâ”€â”€ logs/                # Logs de execuÃ§Ã£o
â”œâ”€â”€ plugins/             # Plugins customizados
â””â”€â”€ config/              # ConfiguraÃ§Ãµes adicionais
```

---

## âš™ï¸ VariÃ¡veis de ambiente importantes

- `AIRFLOW_IMAGE_NAME` â†’ Imagem base do Airflow (default: `apache/airflow:3.0.1`)  
- `AIRFLOW_UID` â†’ UID do usuÃ¡rio host (garante permissÃµes corretas nos volumes)  
- `AIRFLOW_PROJ_DIR` â†’ Pasta base do projeto (default: `.`)  
- `_AIRFLOW_WWW_USER_USERNAME` â†’ UsuÃ¡rio admin (default: `airflow`)  
- `_AIRFLOW_WWW_USER_PASSWORD` â†’ Senha admin (default: `airflow`)  

> Todas podem ser ajustadas no arquivo `.env`.

---

## ğŸ”§ Comandos Ãºteis

```bash
# Subir os serviÃ§os manualmente
docker compose up -d

# Ver logs
docker compose logs -f

# Reiniciar
docker compose restart

# Derrubar (mantÃ©m volumes)
docker compose down
```

---

## ğŸ“Š Health Checks

- Scheduler: `http://localhost:8974/health`  
- API Server: `http://localhost:8080/api/v2/version`  

Esses checks sÃ£o configurados no `docker-compose.yml` e seguem as recomendaÃ§Ãµes da [documentaÃ§Ã£o de health do Airflow](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/check-health.html).

---

## ğŸ‘©â€ğŸ’» Exemplo de DAG mÃ­nima

Para validar que o ambiente estÃ¡ funcionando, crie o arquivo `dags/hello_world.py` com o seguinte conteÃºdo:

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

with DAG(
    dag_id="hello_world",
    start_date=datetime(2025, 1, 1),
    schedule_interval="@daily",
    catchup=False,
    tags=["example"],
) as dag:
    hello = BashOperator(
        task_id="say_hello",
        bash_command="echo 'Hello, Airflow!'"
    )
```

ApÃ³s salvar:
- Acesse a UI do Airflow em [http://localhost:8080](http://localhost:8080) (usuÃ¡rio/senha: `airflow/airflow`).  
- Procure a DAG `hello_world` e execute-a manualmente.  
- O log da tarefa mostrarÃ¡ a saÃ­da **Hello, Airflow!**.  

---

## âš ï¸ Aviso sobre produÃ§Ã£o

Essa configuraÃ§Ã£o Ã© **apenas para desenvolvimento local**.  
Para rodar em produÃ§Ã£o, recomenda-se utilizar:
- [Helm Chart oficial do Airflow](https://airflow.apache.org/docs/helm-chart/stable/index.html)  
- Kubernetes ou outro orquestrador de contÃªineres  
- ConfiguraÃ§Ã£o de alta disponibilidade, autoscaling e seguranÃ§a adequadas.  

---

## ğŸ“š ReferÃªncias oficiais

- [Airflow â€” Docker Compose Quick Start](https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html)  
- [Airflow â€” Health Checks](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/check-health.html)  
- [Airflow â€” Production Deployment](https://airflow.apache.org/docs/apache-airflow/stable/production-deployment.html)  

---

ğŸ‘‰ Esse setup foi pensado para quem quer **subir rÃ¡pido o Airflow localmente** e testar DAGs sem complexidade extra.

---

## ğŸ”— ReferÃªncia adicional

Este projeto foi inspirado tambÃ©m no artigo da Dataquest, que mostra como configurar o **Apache Airflow com Docker localmente**:

ğŸ‘‰ [Setting up Apache Airflow with Docker locally (Dataquest Blog)](https://www-dataquest-io.translate.goog/blog/setting-up-apache-airflow-with-docker-locally-part-i/?_x_tr_sl=en&_x_tr_tl=pt&_x_tr_hl=pt&_x_tr_pto=tc)
