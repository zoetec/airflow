# Apache Airflow em Docker (stack leve para desenvolvimento local)

Este reposit√≥rio traz uma configura√ß√£o do **Apache Airflow** pronta para rodar em ambiente local via **Docker Compose**, utilizando o **PostgreSQL 13** como backend de metadados.

A proposta √© oferecer um ambiente **m√≠nimo e funcional** para desenvolvimento e testes de DAGs, inspirado na [documenta√ß√£o oficial do Airflow](https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html), mas simplificado e otimizado para rodar localmente.

---

## üîé O que est√° inclu√≠do?

- **Airflow Services**:  
  - `airflow-apiserver`  
  - `airflow-scheduler`  
  - `airflow-dag-processor`  
  - `airflow-triggerer`  
  - `airflow-init` (migra√ß√£o + cria√ß√£o de usu√°rio admin)  
  - `airflow-cli` (opcional para debug)  

- **Banco de dados**:  
  - `postgres:13` rodando como servi√ßo dentro do Compose.  

- **Volumes mapeados** para facilitar o desenvolvimento:  
  - `./dags` ‚Üí DAGs  
  - `./logs` ‚Üí Logs  
  - `./plugins` ‚Üí Plugins customizados  
  - `./config` ‚Üí Configura√ß√µes  

---

## üöÄ Como rodar

1. Clone este reposit√≥rio:
   ```bash
   git clone https://github.com/<sua-org>/<seu-repo>.git
   cd <seu-repo>
   ```

2. D√™ permiss√£o de execu√ß√£o ao script:
   ```bash
   chmod +x run.sh
   ```

3. Execute:
   ```bash
   ./run.sh
   ```

Esse script:
- Cria a pasta `airflow-docker` com a estrutura m√≠nima (`dags`, `logs`, `plugins`, `config`).
- Gera um `.env` padr√£o (caso n√£o exista).
- Executa `airflow-init` para preparar o banco de dados no Postgres 13 e criar o usu√°rio admin.
- Sobe todos os cont√™ineres do Airflow em segundo plano.
- Aguarda at√© que o **API Server** esteja saud√°vel em:  
  üëâ [http://localhost:8080/api/v2/version](http://localhost:8080/api/v2/version)

---

## üìÇ Estrutura do projeto

```
.
‚îú‚îÄ‚îÄ docker-compose.yml   # Servi√ßos Airflow + Postgres 13
‚îú‚îÄ‚îÄ run.sh               # Script automatizado para subir o ambiente
‚îú‚îÄ‚îÄ dags/                # Suas DAGs v√£o aqui
‚îú‚îÄ‚îÄ logs/                # Logs de execu√ß√£o
‚îú‚îÄ‚îÄ plugins/             # Plugins customizados
‚îî‚îÄ‚îÄ config/              # Configura√ß√µes adicionais
```

---

## ‚öôÔ∏è Vari√°veis de ambiente importantes

- `AIRFLOW_IMAGE_NAME` ‚Üí Imagem base do Airflow (default: `apache/airflow:3.0.1`)  
- `AIRFLOW_UID` ‚Üí UID do usu√°rio host (garante permiss√µes corretas nos volumes)  
- `AIRFLOW_PROJ_DIR` ‚Üí Pasta base do projeto (default: `.`)  
- `_AIRFLOW_WWW_USER_USERNAME` ‚Üí Usu√°rio admin (default: `airflow`)  
- `_AIRFLOW_WWW_USER_PASSWORD` ‚Üí Senha admin (default: `airflow`)  

> Todas podem ser ajustadas no arquivo `.env`.

---

## üîß Comandos √∫teis

```bash
# Subir os servi√ßos manualmente
docker compose up -d

# Ver logs
docker compose logs -f

# Reiniciar
docker compose restart

# Derrubar (mant√©m volumes)
docker compose down
```

---

## üìä Health Checks

- Scheduler: `http://localhost:8974/health`  
- API Server: `http://localhost:8080/api/v2/version`  

Esses checks s√£o configurados no `docker-compose.yml` e seguem as recomenda√ß√µes da [documenta√ß√£o de health do Airflow](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/check-health.html).

---

## üë©‚Äçüíª Exemplo de DAG m√≠nima

Para validar que o ambiente est√° funcionando, crie o arquivo `dags/hello_world.py` com o seguinte conte√∫do:

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

with DAG(
    dag_id="hello_world",
    start_date=datetime(2025, 1, 1),
    schedule_interval="@daily",
    catchup=False,
    tags=["example"],
) as dag:
    hello = BashOperator(
        task_id="say_hello",
        bash_command="echo 'Hello, Airflow!'"
    )
```

Ap√≥s salvar:
- Acesse a UI do Airflow em [http://localhost:8080](http://localhost:8080) (usu√°rio/senha: `airflow/airflow`).  
- Procure a DAG `hello_world` e execute-a manualmente.  
- O log da tarefa mostrar√° a sa√≠da **Hello, Airflow!**.  

---

## ‚ö†Ô∏è Aviso sobre produ√ß√£o

Essa configura√ß√£o √© **apenas para desenvolvimento local**.  
Para rodar em produ√ß√£o, recomenda-se utilizar:
- [Helm Chart oficial do Airflow](https://airflow.apache.org/docs/helm-chart/stable/index.html)  
- Kubernetes ou outro orquestrador de cont√™ineres  
- Configura√ß√£o de alta disponibilidade, autoscaling e seguran√ßa adequadas.  

---

## üìö Refer√™ncias oficiais

- [Airflow ‚Äî Docker Compose Quick Start](https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html)  
- [Airflow ‚Äî Health Checks](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/check-health.html)  
- [Airflow ‚Äî Production Deployment](https://airflow.apache.org/docs/apache-airflow/stable/production-deployment.html)  

---

üëâ Esse setup foi pensado para quem quer **subir r√°pido o Airflow localmente** e testar DAGs sem complexidade extra.  
